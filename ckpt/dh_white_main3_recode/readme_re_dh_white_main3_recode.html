<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>re-dh-white-main实验记录与分析</title>
    <link rel="stylesheet" href="https://raw.githack.com/Nekasu/ObsidianVault/main/Template/styles.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        dh_white_main3_recode 是一个使用 "具有敦煌风格的图像" 进行风格迁移训练的 Partial_AesFA 实验(以下简称"本实验或该实验或该项目"). 该实验修改了 <a href="../re-dh-white-main/readme_re-dh-white-main.html">re-dh-white-main</a> 中的核心代码 PartConv, 以排查是否是代码出错造成了影响. 此处照搬 2025-02-24 日记中记录, 以展示对代码做出了什么变动.
        <ol>
            <li>
                &ensp; &ensp;<span class="color-huohuo-green">背景介绍:</span>在 <a href="/Diary/2025-01-05.html">/Diary/2025-01-05.html</a> 的“科研”第6项中进行了一项名为 "re-dh-white-main" 实验. 该项目是为了排查是否由于训练轮次过少, 导致"dunhuang_white_main"项目中的 PartailAesFA训练成果 比 原始的 AesFA的成果要差很多. 同时也是为了排查上述相同项目中, 是否是由于训练陷入了局部最优, 最终导致效果很差的原因.(这两个原因也记录在了dunhuang_white_main项目的readme文件中.)<br>
                &ensp; &ensp;<span class="color-huohuo-green">工作内容:</span>现检查该 "re-dh-white-main" 实验的成果, 如果结果依旧难以令人满意, 则需要执行第二项工作, 即修改 PartailAesFA 的代码. <br>
                2025-02-25-15:46 周二: re-dh-white-main 实验成果难以令人满意, 实验记录存储在 Yuhui_4090 服务器中的 /mnt/sda/zxt/3_code_area/code_develop/PartialConv_AesFA/ckpt/dunhuang_white_main/readme_dunhuang_white_main.html 文件中. 现根据该文件的安排进行部分卷积的代码修改工作
            </li>
            <li>
                修改 PartailAesFA 的代码. 尤其是 <span class="color-huohuo-green">部分卷积</span>的代码.  <span class="color-huohuo-green">可以将任务分成多个步骤, 逐个解决.</span>现有如下安排.<br>
                <ol>
                    <li>观察 AesFA_origin 的训练日志, 与 dunhuang_white_main 及其衍生实验 re-dh-white-main、re-dh-white-main2 的训练日志对比, 从表象上观察二者的差别. <span class="color-hutao-red">可以发现, 二者的损失函数值(Loss值)有差别.</span>所以可以认为, 部分卷积放大了图像中的像素值, 导致像素不断变大, 最终导致了损失函数计算时出现问题.</li>
                    <li>根据观察到的表象上的差别, 阅读并运行部分卷积的代码, 以查看是哪里出了问题. 
                        <ol>
                            <li>从数学上检查代码是否出错: 将阅读部分卷积代码, 从数学上分析部分卷积是否会导致像素值变大, 以检测自己的代码是否写错.<br>
                                &ensp;&ensp;<span class="color-hutao-red">结论:</span> 从数学上来说, 部分卷积代码不会导致整体的值不断变大.<br>
                                &ensp;&ensp;<span class="color-hutao-red">论证过程如下.</span> 我们首先观察 部分卷积的核心公式:<br>
                                \[
                                    \begin{equation}
                                        X'_{(i,j)} = \begin{cases}
                                            W^T (X_{(i,j)} \odot M_{i,j})r_{i,j} + b,\quad \sum\limits_{i,j}M_{i,j}>0\\
                                            0, \quad else
                                        \end{cases}
                                    \end{equation}
                                \]
                                可以发现, 其中核心在于公式的第一行, 也即掩膜中有内容的情况. 下面我们介绍一下公式中各个符号的意义.
                                <ul>
                                    <li>
                                        \(W^T\) 表示一个正常的卷积.
                                    </li>
                                    <li>\(X_{(i,j)}\)表示输入图像中, 一个以像素\((i,j)\)为核心, 与卷积核大小相同的像素区域</li>
                                    <li>\(M_{i,j}\)表示\(X_{(i,j)}\)区域对应的掩膜</li>
                                    <li>\(r_{i,j} = \frac{\text{卷积核大小}}{\sum\limits_{i,j}M_{i,j}}\). 当卷积核大小为3*3时, \(r_{i,j} = \frac{9}{\sum\limits_{i,j}M_{i,j}}\in\{\frac91,\frac92,\frac93,\frac94,\frac95,\frac96,\cdots,\frac99\}\). 当掩膜中含 0 的数量越多, 那么该值就越大.<br>
                                        举个例子, 若 掩膜中含 4个 0与 5个 1, 那么该\(r_{i,j}=\frac95\), 若 掩膜中含 1个 0与 8个 1, 那么该\(r_{i,j}=\frac98\). 
                                    </li>
                                </ul>
                                在了解了各个符号的意义后, 我们来逐步看看整体公式的作用. 整个公式可以看成以下几个步骤: 
                                <ol>
                                    <li>部分卷积第一步: 图像矩阵 \(X_{(i,j)}\)与掩膜矩阵 \(M_{i,j}\)之间的逐元素相乘. 该运算表明, 图像矩阵\(X_{i,j}\)按掩膜\(M_{i,j}\)的指导, 将其中部分像素设置为0, 以下是一个例子:
                                        \[
                                            \begin{equation}
                                            \begin{aligned}
                                                X_{(i,j)}\odot M_{i,j} &= \begin{bmatrix}255&255&255\\255&255&255\\255&255&255\end{bmatrix}\odot \begin{bmatrix}1&0&0\\0&1&1\\1&0&1\end{bmatrix}\\
                                                &= \begin{bmatrix}255&0&0\\0&255&255\\255&0&255\end{bmatrix}
                                            \end{aligned}
                                            \end{equation}
                                        \]
                                        该步骤中丢失了部分信息
                                    </li>
                                    <li>部分卷积第二步: 随后进行一个再简单不过的卷积运算 \(W^T (X_{(i,j)} \odot M_{i,j})\), 由于卷积是<span class="color-DrRatio-blue">对应位置相乘并相加</span>的运算, 所以该步骤的结果是一个数, 而非一个矩阵.</li>
                                    <li>
                                        部分卷积第三步: 在第一步中, 我们提到, 这种与掩膜运算的结果导致了信息丢失, 所以作者想将丢失的信息补回来, 而这正是通过 系数\(r_{i,j}\)做到的.
                                        举个例子, 若 掩膜中含 4个 0与 5个 1, 那么表明图像中丢失了4个位置的信息, 仅保留了5个位置的信息. 为了补全获取全部9个位置的信息, 我们将结果 \(\times \frac95\). 也即我们认为, 当前的结果中, 仅有5个位置的信息, 为了保留9个位置的信息, 需要将除以5, 再乘以9.<br>
                                        尽管 \(r_{i,j}\)是一个大于1的数, 但是由于一开始信息的丢失, 导致计算结果本来就小了一些, 所以这一步也不应该导致数据量的爆炸.
                                    </li>
                                </ol>
                                根据以上从数学角度的分析, 可以知道, 部分卷积是不应该导致数据量膨胀的. 所以应该是我编写的代码出现了问题.
                            </li>
                            <li>从实验上检查代码是否出错: 使用一个简单的 3*3 张量(Tensor)测试部分卷积代码是否正确.
                                <ol>
                                    <li><span class="color-hutao-red">问题1</span>: PartConv.py 105行. \(r_{i,j}\) 的分母 \(sum(I)\)不是kernel_size \(\times\) kernel_size, 还应与卷积核的"厚度"有关.<br>
                                        <span class="color-huohuo-green">解决: 目前以将卷积核"厚度"(即输入维度)纳入 \(sum(I)\) 的计算中.</span>
                                    </li>
                                    <li><span class="color-hutao-red">问题2</span>: PartConv.py 109行. 计算sum_mask的代码也可能有误, 这些错误记录在平板中了, 吃完饭回来看看.
                                        <span class="color-huohuo-green">解决: 目前已经完善了 sum_mask 代码的编写. 具体来说, 同样添加了输入维度的信息.</span>
                                    </li>
                                    <li>问题3: 可能是训练数据有问题, 晚饭后使用训练数据检查代码.</li>
                                </ol>
                            </li>
                            <li>同时不再使用 PartConv.py 中的测试代码, 而是直接使用 train.py 进行测试, 以进行实际的测试. 由于数据维度太大, 无法完全观察, 所以仅观察必要数据的最大与最小值<br>
                                &ensp;&ensp;<span class="color-kachina-yellow">2025-03-04-20:20 周二</span>: 训练时发现, 如果在PartialConv 中乘以系数矩阵 ratio, 则会在很短的时间内出现 nan 问题. 而不与系数矩阵相乘时, 观察了较长的一段时间后, 发现并未出现nan问题. 推测为 系数矩阵ratio 计算有误.<br>
                                &ensp;&ensp;<span class="color-kachina-yellow">2025-03-04-20:32 周二</span>: 打印后发现, 系数矩阵并非是核心问题, 真正的问题在 sum_mask 计算错误. 在某一个时刻, 可以发现 sum_mask 的值变为了带有小数的值, 这与常识相悖, 如下图所示.<br>
                                <img src="https://raw.githubusercontent.com/Nekasu/Blog_pics/main/20250304210419.png"/>
                                &ensp;&ensp;<span class="color-kachina-yellow">2025-03-04-21:11 周二:</span> 根据 deepseek 的提示, 我打印了 conv_1 卷积核的最大最小值, 以检查该卷积核是否全为1. 结果发现 conv_1 中数据并非全部为1. 那么 ratio计算问题、sum_mask计算问题的核心, 均在于 conv_1 中数据不全为1. 仔细检查后发现, 代码中存在一句 self.conv_1 = self.conv, 将这一句删除, 并将sum_mask进行了四舍五入、限制最小值为+0.0的处理后, 上述的 ratio计算问题、sum_mask计算问题均在短期内得到解决. 需要重新训练一次该项目, 以检查上述两个计算问题是否真正被解决. <br>
                            </li>
                        </ol>
                    </li>
                    <li>
                        <span class="color-kachina-yellow">2025-03-04-21:31 周二</span>: 代码问题暂时得到解决, 需要训练后再做检查. 新训练项目记作 "dh_white_main3_recode"
                    </li>
                </ol>
            </li>
        </ol>
        <h1>训练信息</h1>
        <ul>
            <li>该实验与其父实验<a href="../re-dh-white-main/readme_re-dh-white-main.html">re-dh-white-main</a>使用相同的训练集. 训练用数据集信息如下：
                <ul>
                    <li>content_dir = '/mnt/sda/Dataset/Detection/COCO/train2017' </li>
                    <li>style_dir = '/mnt/sda/Dataset/style_image/dunhuang_style/crop_256/main_white/origin' </li>
                    <li>mask_dir = '/mnt/sda/Dataset/style_image/dunhuang_style/crop_256/main_white/mask' </li>
                 </ul>
            </li>
            <li>
                训练数据记录在<a href="./log.txt">这个txt文件</a>中.
            </li>
        </ul>
        <hr>
        <h1>生成结果</h1>
        <ul>
            <li> 本次训练结果为  ./ckpt/dh_white_main3_recode/model_iter_160000_epoch_22.pth, 现将该 .pth 文件复制并重命名为 main.pth, 以符合测试文件 test.py 的要求. </li>
            <li> 
                测试用数据集信息如下:
                <ul>
                    <li> content_dir = '/mnt/sda/zxt/3_code_area/code_develop/PartialConv_AesFA/imgs/contents/full' </li>
                    <li> style_dir = '/mnt/sda/zxt/3_code_area/code_develop/PartialConv_AesFA/imgs/styles' </li>
                    <li> mask_dir = '/mnt/sda/zxt/3_code_area/code_develop/PartialConv_AesFA/imgs/masks' + '/' + mod </li>
                </ul>
            </li>
        </ul>
        &ensp;&ensp; 使用本次训练成果生成的 <span class="color-huohuo-green">主体图像</span> 存储于 ./output/dh_white_main3_recode/256/main 中, 可在对应文件夹下找到 .html 文件进行查看<br>
        &ensp;&ensp; 使用本次训练成果生成的 <span class="color-huohuo-green">背景图像</span> 存储于 ./output/dh_white_main3_recode/256/back 中, 可在对应文件夹下找到 .html 文件进行查看<br>
        <hr>
        <h1>评价</h1>
        效果不错, 是可以开始写论文的程度了. 下面可以考虑进行进一步的修改, 比如加入不透明度的处理机制等. 不过加入不透明度的机制还是等论文写完投稿后再写代码吧.
        <hr>
        <h1>结论</h1>
        根据实验结果, 开始撰写论文.
    </div>
</body>
</html>